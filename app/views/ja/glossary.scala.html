<div class="toc cf">
    <h2>目次</h2>
    <ul>
        <li><a href="#Asynchronous">非同期</a></li>
        <li><a href="#Back-Pressure">バック・プレッシャー</a></li>
        <li><a href="#Batching">バッチ処理</a></li>
        <li><a href="#Delegation">委譲</a></li>
        <li><a href="#Component">コンポーネント</a></li>
        <li><a href="#Elasticity">弾力性（スケーラビリティと対比して</a></li>
        <li><a href="#Failure">障害（エラーと対比して</a></li>
        <li><a href="#Isolation">隔離（と封じ込め</a></li>
        <li><a href="#Location-Transparency">位置透過性</a></li>
    </ul>
    <ul>
        <li><a href="#Message-Driven">メッセージ駆動（イベント駆動と対比して</a></li>
        <li><a href="#Non-Blocking">ノンブロッキング</a></li>
        <li><a href="#Protocol">プロトコル</a></li>
        <li><a href="#Replication">レプリケーション</a></li>
        <li><a href="#Resource">リソース</a></li>
        <li><a href="#Scalability">スケーラビリティ</a></li>
        <li><a href="#System">システム</a></li>
        <li><a href="#User">ユーザ</a></li>
    </ul>
</div>


<h2 id="Asynchronous"><a href="#Asynchronous" class="link-icon">@image("link-icon.png")</a>非同期</h2>
<p>オックスフォード英語辞典は、<strong>非同期</strong> (asynchronous) を「同時に存在したり起きたりしないこと」と定義している。リアクティブ宣言の文脈では、「クライアントからサービスへ送信されたリクエストが、送信後の任意の時点で処理されること」を意味する。送信先のサービス内でのリクエスト処理の実行を直接クライアントが観測したり、それに対して同期を取ることはできない。非同期の対義語である同期処理では、サービスがリクエストを処理するまでクライアントは自身の実行を再開しない。</p>

<h2 id="Back-Pressure"><a href="#Back-Pressure" class="link-icon">@image("link-icon.png")</a>バック・プレッシャー</h2>
<p>ある<a href="#Component">コンポーネント</a>が全体に追いつけなくなった場合、<a href="#System">システム</a>全体として何らかの対処をする必要がある。過負荷状態のコンポーネントが壊滅的にクラッシュしたり、制御無くメッセージを損失することは許されない。処理が追いつかなくなっていて、かつクラッシュすることも許されないならば、コンポーネントは上流のコンポーネント群に自身が過負荷状態であることを伝えて負荷を減らしてもらうべきだ。この<strong>バック・プレッシャー</strong> (back-pressure) と呼ばれる仕組みは、過負荷の下でシステムを崩壊させず緩やかに応答を続ける重要なフィードバック機構だ。バック・プレッシャーはユーザまで転送してもよく、その場合、即応性 (resilient) は低下するが負荷の下でのシステムの耐障害性が保証される。また、システムがその情報を使って自身に他のリソースを振り向け、負荷分散を促すこともできる。<a href="#Elasticity">弾力性</a>を参照。</p>

<h2 id="Batching"><a href="#Batching" class="link-icon">@image("link-icon.png")</a>バッチ処理</h2>
<p>現在のコンピュータは同じタスクを繰り返し実行することに最適化されている。命令キャッシュや分岐予測によって、クロック周波数を一定に保ったまま一秒間に処理できる命令数を増加することができるためだ。そのため、同じ CPU コアへ異なるタスクを立て続けに与えてしまうと、この最適化によって得られる性能をフルに引き出すことができない。もし可能ならば、異なるタスクを交互に実行する頻度を少なくするようにプログラムを構成するべきだ。つまり、データ要素を一つの集合にして<strong>バッチ</strong> (batching) で処理したり、異なる処理ステップを専用のハードウェアスレッドで実行したりすればよい。</p>

<p>同期や協調を必要とする外部<a href="#Resource">リソース</a>を使用する際も、同様の論理が当てはまる。永続的ストレージ機器が提供する I/O 帯域幅は、単一のスレッド（と CPU コア）がコマンドを発行することにより、全てのコアに帯域幅を争わせる場合よりも劇的に改善する。この方法のさらなる利点は、機器へのエントリポイントが単一なので、機器にとって最適なアクセスパターンへより適合するように操作の順序を入れ替えられることだ。</p>
<p>さらに、バッチ処理により I/O のような高価な操作や高価な計算のコストを分配できることがある。例えば、複数のデータ要素を同じネットワークパケットやディスクブロックにまとめることで、効率の向上と利用の削減ができる</p>

<h2 id="Delegation"><a href="#Delegation" class="link-icon">@image("link-icon.png")</a>委譲</h2>
<p>タスクを<a href="#Asynchronous">非同期</a>に他の<a href="#Component">コンポーネント</a>へ<strong>委譲</strong> (delegation) すると、そのタスクの実行は委譲先のコンポーネントのコンテキストで行われる。つまり、委譲されたタスクの実行は異なるエラー処理コンテキスト上や、異なるスレッド内、異なるプロセス内、異なるネットワークノード上で行われることがある。コンポーネントは、タスクを処理する責任をその他のコンポーネントへ委譲して他の処理を実行できるし、あるいは障害処理や進捗報告といった動作が必要な場合に、委譲したタスクの進捗を観察することもできる。</p>


<h2 id="Component"><a href="#Component" class="link-icon">@image("link-icon.png")</a>コンポーネント</h2>
<p>ここで説明するモジュラー・ソフトウェア・アーキテクチャ (modular software architecture) は、とても古くからある概念だ。例えば <a target="_blank" href="https://www.cs.umd.edu/class/spring2003/cmsc838p/Design/criteria.pdf">Parnas (1972)</a> を見よ。ここでは、モジュールの代わりに<strong>「コンポーネント」</strong> (component) という用語を採用する。これは、コンポーネントの方が意味的に「仕切られた区画」に近いからだ。それぞれのコンポーネントは自立していて、カプセル化されており、他のコンポーネントから<a href="#Isolation">隔離</a> されている。この概念が最も当てはまるのはシステムの実行時特性に対してだが、一般的に同様にソースコードのモジュール構造にも反映される。異なるコンポーネントは、同じソフトウェアモジュールを用いて共通のタスクを実行するかもしれないが、そのとき、それぞれコンポーネントの最上位の動作を定義するプログラムコードはコンポーネント自身のモジュールだ。コンポーネント境界は、問題領域の<a href="http://martinfowler.com/bliki/BoundedContext.html" target="_blank">コンテキスト境界</a> (bounded context) と密接なつながりがある。つまり、隔離が保たれていると、システム設計は問題領域を反映しやすいので容易に進化できる。メッセージの<a href="#Protocol">プロトコル</a>は、コンテキスト（コンポーネント）境界の間の自然なマッピングと通信レイヤを提供する。</p>


<h2 id="Elasticity"><a href="#Elasticity" class="link-icon">@image("link-icon.png")</a>弾力性（スケーラビリティと対比して）</h2>
<p><strong>弾力性</strong> (elasticity) とは、変化する要求を満たすために、リソースを比例的に追加または除去して、システムのスループットを自動的にスケールアップまたはスケールダウンすることだ。実行時におけるリソースの動的な追加や除去の恩恵を受けるには、システムはスケーラブル（<a href="#Scalability">スケーラビリティ</a>を参照）である必要がある。弾力性は、つまり、スケーラビリティに対して自動的な<a href="#Resource">リソース</a>管理の概念を加えて拡張したものだ。</p>

<h2 id="Failure"><a href="#Failure" class="link-icon">@image("link-icon.png")</a>障害（エラーと対比して）</h2>
<p><strong>障害</strong> (failure) はサービス内での予期しないイベントであり、サービスが正常に動作を続けられなくなる。障害が起きるとたいてい、現在の（場合によっては後に続く全ての）クライアントリクエストに応答できなくなる。これは、予期され状況に合わせてコード化されるエラーとは対照的だ。例えば、入力の検証中にエラーが見つかれば、それはメッセージの通常の処理の一部としてクライアントへ伝えられるだろう。障害は予期できないので、<a href="#System">システム</a>が同等の動作レベルへ復旧しようとする前に介入する必要がある。これは、障害が致命的ではない場合でも、障害の後ではシステムのいくつかの能力が減少しているからだ。エラーは正常な動作の一部として予期されており、即座に対処されるので、システムはエラーの後でも同等の能力で動作を維持できる</p>
<p>障害の例として、ハードウェアの誤動作や、リソースの枯渇によるプロセスの終了、内部状態を破損させるようなプログラムの欠陥が挙げられる。</p>

<h2 id="Isolation"><a href="#Isolation" class="link-icon">@image("link-icon.png")</a>隔離（と封じ込め）</h2>
<p><strong>隔離</strong> (isolation) は、時間または空間における分離 (decoupling) によって定義できる。時間的分離とは、送信者と受信者がそれぞれ独立したライフサイクルを持てるという意味で、通信を可能とするために同時に存在している必要がない。これは、<a href="#Component">コンポーネント</a>間に<a href="#Asynchronous">非同期</a>境界を追加して<a href="#Message-Driven">メッセージパッシング</a> (message-passing) で通信することで可能になる。（<a href="#Location-Transparency">位置透過性</a>として定義される）空間的分離とは、送信者と受信者を同じプロセス内で実行する必要がないという意味だ。しかし、運用部門やランタイム自身が決めた場所が最も効率的だったとしても、それはアプリケーションの生存期間中に変わりうる。</p>
<p>真の隔離は、オブジェクト指向言語において最も見られるカプセル化の概念を超えたところにあり、これらのものを区切って封じ込めることができる:</p>
<ul>
    <li>状態と動作: シェアード・ナッシングな設計が可能になると共に、（<a target="_blank" href="http://www.perfdynamics.com/Manifesto/USLscalability.html">普遍的スケーラビリティの法則</a> (Universal Scalability Law) が定義するような）競合および一貫性のコストを最小化する。</li>
    <li>故障: <a href="#Failure">エラー</a>を他のコンポーネントへ転送することなく、細粒度のレベルで捕捉し、シグナルし、管理できる。</li>
</ul>
<p>明確に定義された<a href="#Protocol">プロトコル</a>を介した通信はコンポーネント間の強い隔離を実現し、それにより疎結合になるので、システムの理解、拡張、テスト、進化がより容易になる。</p>

<h2 id="Location-Transparency"><a href="#Location-Transparency" class="link-icon">@image("link-icon.png")</a>位置透過性</h2>
<p><a href="#Elasticity">弾力性</a>のあるシステムとは適応性のあるシステムだ。それは要求の変化に対して継続的に対応し、緩やかかつ効率的にスケールを増減できる必要がある。一つの鍵となる洞察は、ここでは全てが分散コンピューティングであるということだ。そのことに気付くと、この問題は非常に簡潔になる。このことは、システムが実行されているのがシングルノード(QPI リンクを介して通信する複数の独立した CPU を備える)上であろうと、複数ノードのクラスタ（ネットワークを介して通信する独立したマシンを備える）上であろうと、同様に当てはまる。この事実から言えるのは、マルチコア上での垂直方向のスケーリングと、クラスタ上での水平方向のスケーリングとの間にコンセプトの違いはないということだ。</p>

<p>もし全ての<a href="#Component">コンポーネント</a>に機動性 (mobility) があり、任意の場所に配備が可能ならば、ローカル通信は単なる最適化であり、あらかじめシステムの静的トポロジや配備モデルを定義しておく必要がなくなる。こうした決定を運用の人員やランタイムに任せることで、システムの適応化や最適化をそれがどのように使われるか次第で行うことができる。</p>

<p>この<a href="#Asynchronous">非同期性</a>と<a href="#Message-Driven">メッセージパッシング</a>により可能になる空間的分離（<a href="#Isolation">隔離</a>の項での定義を見よ）と、ランタイムインスタンスとその参照の分離は、我々が<strong>位置透過性</strong> (location transparency) と呼んでいるものだ。位置透過性は”透過的な分散コンピューティング”としばしば誤解されるが、実際にはその反対だ。我々は、プロセス内のメソッド呼び出しを（RPC や XA のように）ネットワーク上でエミュレートするのではなく、ネットワークとその制約の全て（部分障害、ネットワーク分断、メッセージの喪失、そして非同期かつメッセージに基づくことによる性質）を受け入れて、プログラミングモデルの第一級市民として扱う。我々の位置透過性に対する見方は、Waldo らによる <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7628" target="_blank">A Note On Distributed Computing</a> と完全に一致する。</p>

<h2 id="Message-Driven"><a href="#Message-Driven" class="link-icon">@image("link-icon.png")</a>メッセージ駆動（イベント駆動と対比して）</h2>
<p>メッセージは特定の宛先へと送られるデータ項目である。イベントは既定の状態に到達した<a href="#Component">コンポーネント</a>から発生するシグナルである。<strong>メッセージ駆動</strong> (message-driven) のシステムでは、アドレス可能な受信者はメッセージの到着を待ってそれに反応するか、さもなくば休止状態になる。イベント駆動のシステムでは、通知のリスナーはイベントの発生源に取り付けられ、イベントが発生した時に呼び出される。つまり、イベント駆動システムがアドレス可能なイベントの発生源に焦点を当てるのに対して、メッセージ駆動システムはアドレス可能な受信者に専心している。メッセージは、自身のペイロードに符号化されたイベントを持つことができる。</p>

<p>イベント駆動システムではイベント消費チェインの短命な性質故に、耐障害性の達成はより難しい。処理が開始されると共に取り付けられたリスナーはイベントに反応して結果へと変換する。このとき、リスナーは一般的に成功や<a href="#Failure">障害</a>を直接に処理して元のクライアントへ報告を返す。一方で、コンポーネントの障害に反応してその機能を正常に回復させるには、これらの障害が短命なクライアントリクエストと結びつかないようにし、しかしあらゆるコンポーネントの健康状態に反応するように扱う必要がある。</p>

<h2 id="Non-Blocking"><a href="#Non-Blocking" class="link-icon">@image("link-icon.png")</a>ノンブロッキング</h2>
<p>並行プログラミングにおいて、一つのリソースを巡って競争する複数のスレッドが、それらのリソースを相互に排他的に保護することで無期限に実行が延期されるとき、あるアルゴリズムは<strong>ノンブロッキング</strong> (non-blocking) とみなされる。このことは、実際には API として明示される。API は、<a href="#Resource">リソース</a>が利用可能ならアクセスさせ、そうでなければ直ちに返って、リソースが現時点では利用できなかったり、操作が開始されて未だ完了していないことを呼び出し元へ伝える。リソースに対するノンブロッキング API では、呼び出し元は、リソースが利用可能になるまでブロックして待つ代わりに他の仕事をすることができる。加えて、リソースのクライアントはリソースが利用可能になるか操作が完了したときに自身へ通知するよう登録することができる。</p>

<h2 id="Protocol"><a href="#Protocol" class="link-icon">@image("link-icon.png")</a>プロトコル</h2>
<p><strong>プロトコル</strong> (protocol) は、<a href="#Component">コンポーネント</a>間でのメッセージの交換や転送に対する取り扱いと作法を定義する。プロトコルの策定は、メッセージ交換に参加する者同士の関係、プロトコルの累積的な状態、そして送信可能なメッセージの集合によってなされる。つまりプロトコルは、参加者が任意の時点で他の参加者へ送信できるメッセージを定義する。プロトコルは、交換におけるいくつかの共通の形体（要求-応答型、（HTTP におけるような）繰り返される要求-応答型、出版-購読型、プッシュ型やプル型のストリーム）に分類できる。</p>

<p>ローカルなプログラミングインタフェースと比べて、プロトコルはより一般的だ。なぜなら、インタフェースは呼び出し元と受信者の間の相互作用を一つずつしか指定できないのに対して、プロトコルは二人以上の参加者を含むことができ、またメッセージ交換の状態の進行を予見するからだ。</p>

<p>注目すべきは、ここで定義したプロトコルはどんなメッセージを送ることができるかのみを指定しており、どうやって送るかは指定していないということだ。コンポーネントがプロトコルを使用する際に、符号化や復号を行うコーデックや転送メカニズムといった実装の詳細は透過的だ。</p>

<h2 id="Replication"><a href="#Replication" class="link-icon">@image("link-icon.png")</a>レプリケーション</h2>
<p><a href="#Component">コンポーネント</a>を異なる場所で同時に実行することを<strong>レプリケーション</strong> (replication) と呼ぶ。つまり、コンポーネントは異なるスレッドやスレッドプール、プロセス、ネットワークノード、コンピューティングセンターで実行される。レプリケーションは<a href="#Scalability">スケーラビリティ</a>（受信したワークロードをコンポーネントの複数のインスタンスに分散する）と耐障害性（受信したワークロードを複数のインスタンスに複製して、同じリクエストを並列に処理する）を提供する。これらのやり方は組み合わせることができ、例えば、受信した負荷によってインスタンスの総数が変化しても、コンポーネントのあるユーザに関する全てのトランザクションが二つのインスタンスで実行されることを保証する、といったことができる（<a href="#Elasticity">弾力性</a>を見よ）。</p>

<h2 id="Resource"><a href="#Resource" class="link-icon">@image("link-icon.png")</a>リソース</h2>
<p><a href="#Component">コンポーネント</a>が自身の機能を実行するのに依存するあらゆるものが<strong>リソース</strong> (resource) であり、コンポーネントが必要とするのに従って供給されなければならない。これらのリソースには CPU 割り当て、メインメモリ、永続化ストレージなどがあり、同様にネットワーク帯域、メインメモリ帯域、CPU キャッシュ、ソケット間 CPU リンク、高信頼なタイマーとタスクスケジューリングサービス、その他の入出力デバイス、データベースやネットワークファイルシステムのような外部サービス、などが含まれる。必要なリソースが不足していると必要なときにコンポーネントが機能しないので、これらの全てのリソースについて<a href="#Elasticity">弾力性</a>と耐障害性を考慮する必要がある。</p>

<h2 id="Scalability"><a href="#Scalability" class="link-icon">@image("link-icon.png")</a>スケーラビリティ</h2>
<p>システムが自身の性能を向上させるためにさらなる計算<a href="#Resource">リソース</a>を利用する能力は、スループットの向上のリソースの増加に対する比率によって測定される。完全な<strong>スケーラビリティ</strong> (scalability) があるシステムでは両者の数値は比例するので、リソースの割り当てが二倍になればスループットも二倍になる。ボトルネックやシステム内の同期点は、一般にスケーラビリティが制約される原因となる。<a target="_blank" href="http://blogs.msdn.com/b/ddperf/archive/2009/04/29/parallel-scalability-isn-t-child-s-play-part-2-amdahl-s-law-vs-gunther-s-law.aspx">アムダールの法則とグンサーの普遍的スケーラビリティモデル</a> を見よ。</p>


<h2 id="System"><a href="#System" class="link-icon">@image("link-icon.png")</a>システム</h2>
<p><strong>システム</strong> (system) は<a href="#User">ユーザ</a>やクライアントにサービスを提供する。システムはその大小に関わらず、多数またはごく少数の<a href="#Component">コンポーネント</a>から成る。システムの全てのコンポーネントは協調してサービスを提供する。多くの場合、コンポーネントは同じシステム内でクライアント−サーバ関係にある（フロントエンドコンポーネントがバックエンドコンポーネントに依存している場合など）。システムは共通の耐障害モデルを共有する。つまり、あるコンポーネントの<a href="#Failure">障害</a>は他のコンポーネントへ<a href="#Delegation">委譲</a>してシステム内で対処する。これは、システム内のコンポーネントグループをサブシステムとみなして、その機能や<a href="#Resource">リソース</a>、障害モデルをシステムの他の部分から<a href="#Isolation">隔離</a>するのに有用だ。</p>

<h2 id="User"><a href="#User" class="link-icon">@image("link-icon.png")</a>ユーザ</h2>
<p>サービスの何らかの消費者を指して使う<strong>「ユーザ」</strong> (user) という用語は、ここでは、人間やその他のサービスのことである。</p>